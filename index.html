<!DOCTYPE html>
<html lang="en">
<head>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>
        // Add code loading functionality
        async function loadCodeSnippet(filePath, codeBlockId) {
            try {
                const response = await fetch(filePath);
                if (!response.ok) {
                    throw new Error(`Failed to load code snippet: ${response.status} ${response.statusText}`);
                }
                const code = await response.text();
                const codeElement = document.getElementById(codeBlockId);
                if (codeElement) {
                    codeElement.textContent = code;
                    hljs.highlightElement(codeElement);
                } else {
                    console.error(`Code element with ID ${codeBlockId} not found`);
                }
            } catch (error) {
                console.error('Error loading code snippet:', error);
                const codeElement = document.getElementById(codeBlockId);
                if (codeElement) {
                    codeElement.textContent = `// Error loading code snippet: ${error.message}`;
                    hljs.highlightElement(codeElement);
                }
            }
        }

        document.addEventListener('DOMContentLoaded', (event) => {
            // Highlight any pre-filled code blocks
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
            
            // Load all code snippets that have data attributes
            document.querySelectorAll('code[data-src]').forEach((codeBlock) => {
                const filePath = codeBlock.getAttribute('data-src');
                loadCodeSnippet(filePath, codeBlock.id);
            });
        });
    </script>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Keyboard Synthesizer with Drums and GUI</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
        }
        
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #7f8c8d;
            font-size: 1.2em;
            margin-bottom: 20px;
        }
        
        .author-info {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        .author-image {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 15px;
            background-color: #ddd;
        }
        
        .author-details {
            text-align: left;
        }
        
        .author-name {
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .post-date {
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        .featured-image {
            width: 100%;
            height: 600px;
            object-fit: cover;
            margin-bottom: 30px;
            background-color: #ddd;
        }
        
        section {
            margin-bottom: 40px;
        }
        
        h2 {
            color: #3498db;
            margin-top: 30px;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 10px;
        }
        
        p {
            margin-bottom: 20px;
        }
        
        .project-image {
            width: 100%;
            max-height: 350px;
            object-fit: contain;
            margin: 20px 0;
            background-color: #ddd;
        }
        
        .caption {
            text-align: center;
            color: #7f8c8d;
            font-style: italic;
            margin-top: 5px;
            margin-bottom: 30px;
        }
        
        blockquote {
            border-left: 5px solid #3498db;
            padding-left: 20px;
            margin-left: 0;
            color: #555;
            font-style: italic;
        }
        
        .conclusion {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin-top: 40px;
        }
        
        footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ecf0f1;
            color: #7f8c8d;
            font-size: 0.9em;
        }

        .components-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0 30px 0;
        }

        .components-table th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
            padding: 10px;
            text-align: left;
            border: 1px solid #ddd;
        }

        .components-table td {
            padding: 8px 10px;
            border: 1px solid #ddd;
            vertical-align: top;
        }

        .components-table tr:nth-child(even) {
            background-color: #f2f2f2;
        }

        .components-table tr:hover {
            background-color: #e9f7fe;
        }
        pre {
            background-color: #282c34;
            border: 1px solid #3e4451;
            border-left: 3px solid #3498db;
            color: #abb2bf;
            page-break-inside: avoid;
            font-family: "SFMono-Regular", Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace;
            font-size: 14px;
            line-height: 1.6;
            margin-bottom: 1.6em;
            max-width: 100%;
            overflow: auto;
            padding: 1em 1.5em;
            display: block;
            word-wrap: break-word;
            border-radius: 0 0 4px 4px;
            max-height: 400px; /* Makes it scrollable after this height */
        }

        code {
            font-family: "SFMono-Regular", Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace;
            background-color: #f0f0f0;
            border-radius: 3px;
            padding: 2px 4px;
            color: #e06c75; /* Inline code color */
        }

        pre code {
            background-color: transparent;
            border-radius: 0;
            padding: 0;
            color: inherit;
        }

        .code-header {
            background-color: #3498db;
            color: white;
            padding: 8px 15px;
            font-family: "SFMono-Regular", Consolas, Monaco, monospace;
            font-weight: bold;
            border-top-left-radius: 4px;
            border-top-right-radius: 4px;
            margin-bottom: 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .code-container {
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        /* Syntax highlighting colors - basic set */
        .hljs-keyword { color: #c678dd; } /* purple */
        .hljs-built_in { color: #e6c07b; } /* yellow-ish */
        .hljs-type { color: #e6c07b; } /* yellow-ish */
        .hljs-literal { color: #56b6c2; } /* teal */
        .hljs-number { color: #d19a66; } /* orange */
        .hljs-regexp { color: #98c379; } /* green */
        .hljs-string { color: #98c379; } /* green */
        .hljs-subst { color: #e06c75; } /* red */
        .hljs-symbol { color: #61aeee; } /* blue */
        .hljs-class { color: #e6c07b; } /* yellow-ish */
        .hljs-function { color: #61aeee; } /* blue */
        .hljs-title { color: #61aeee; } /* blue */
        .hljs-params { color: #abb2bf; } /* default text */
        .hljs-comment { color: #5c6370; font-style: italic; } /* gray, italicized */
    </style>
</head>
<body>
    <header>
        <h1>Keyboard Synthesizer with Drums and GUI</h1>
        <div class="subtitle">3C10 Group 7</div>
        
        <div class="author-info">
            <img src="imgs/TCD.jpg" alt="Author photo" class="author-image">
            <div class="author-details">
                <div class="author-name">Ruairi Mullally, Otis Doran, Aidan McNeill, Brandon Kekedjian</div>
                <div class="post-date">April 22, 2025</div>
            </div>
        </div>
    </header>
    
    <img src="imgs/full_deck.jpeg" alt="Featured image" class="featured-image">
    
    <section class="introduction">
        <h2>Introduction</h2>
        <p>This DIY digital synthesizer and drum set project is perfect for any music enthusiast, 
            hacker, or programmers who are interested in digital signal processing (DSP), modern music production, electronics and programming.
            Use an Arduino and Rasperry PI Pico (optional) to create your own DJ deck, complete with a synthesizer, effects (attack, delay, sustain, release)
            , keyboard and drums. Develop some applied practical skills and add your own twists following along with this project!
        </p>
        
        <blockquote>
            "The most exciting phrase to hear in science, the one that heralds new discoveries, is not 'Eureka!' but 'That's funny...'" - Isaac Asimov
        </blockquote>
    </section>

    <section class="required-materials">
        <h2>What you'll need:</h2>
        <p>Below is a table of the main parts you will need to create the basic elements of this project. Don't fret! If you do not have exactly resistors or capacitors, you can experiment with designing your own filters, etc.</p>
        
        <table class="components-table">
            <thead>
                <tr>
                    <th>Component</th>
                    <th>Quantity</th>
                    <th>Specifications</th>
                    <th>Purpose</th>
                </tr>
            </thead>
            <tbody>
                <!-- Core Electronics -->
                <tr class="section-header">
                    <td colspan="4"><strong>Core Electronics</strong></td>
                </tr>
                <tr>
                    <td>Arduino Nano 33 IOT</td>
                    <td>1</td>
                    <td>Or compatible microcontroller (Uno, etc.)</td>
                    <td>Main processor for the synthesizer</td>
                </tr>
                <tr>
                    <td>Raspberry PI Pico</td>
                    <td>1</td>
                    <td>Or compatible microcontroller</td>
                    <td>Main processor for drums and GUI</td>
                </tr>
                <tr>
                    <td>Breadboard</td>
                    <td>1</td>
                    <td>Full-size recommended, multiple may be helpful</td>
                    <td>For prototyping the circuit</td>
                </tr>
                <tr>
                    <td>Jumper Wires</td>
                    <td>20+</td>
                    <td>Various lengths, female connectors may be helpful</td>
                    <td>Connecting components</td>
                </tr>
                
                <!-- Keyboard/Input Section -->
                <tr class="section-header">
                    <td colspan="4"><strong>Keyboard/Input Components</strong></td>
                </tr>
                <tr>
                    <td>Keypad</td>
                    <td>1</td>
                    <td>Alternatively use 8+ push buttons</td>
                    <td>Keyboard keys</td>
                </tr>
                <tr>
                    <td>Potentiometers</td>
                    <td>6</td>
                    <td>10kΩ linear</td>
                    <td>Parameter controls for keyboard (attack, sustain, release, etc.)</td>
                </tr>
                <tr>
                    <td>Pull-down Resistors</td>
                    <td>8+</td>
                    <td>10kΩ</td>
                    <td>For button debouncing (only necessary if you use push-buttons rathe than keypad)</td>
                </tr>
                
                <!-- Synthesizer/Sound Generation -->
                <tr class="section-header">
                    <td colspan="4"><strong>Synthesizer Components</strong></td>
                </tr>
                <tr>
                    <td>Digital to Analogue Converter (DAC)</td>
                    <td>1</td>
                    <td><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/22250A.pdf">MCP499</a> (12 bit DAC) or similar</td>
                    <td>Signal generation</td>
                </tr>
                <tr>
                    <td>Op-Amp</td>
                    <td>1</td>
                    <td><a href="https://www.analog.com/en/products/max417.html">MAX417</a> or similar</td>
                    <td>DAC signal conditioning</td>
                </tr>
                
                <tr>
                    <td>Resistors</td>
                    <td>2</td>
                    <td>10kΩ</td>
                    <td>For RC filter</td>
                </tr>
                <tr>
                    <td>Capacitor</td>
                    <td>1</td>
                    <td>1μF</td>
                    <td>For RC filter</td>
                </tr>
                
                <!-- Output Section -->
                <tr class="section-header">
                    <td colspan="4"><strong>Output Components</strong></td>
                </tr>
                <tr>
                    <td>Speaker</td>
                    <td>1</td>
                    <td>8Ω</td>
                    <td>Audio output</td>
                </tr>
                <tr>
                    <td>Audio Power Amplifier</td>
                    <td>1</td>
                    <td><a href= "https://www.ti.com/lit/ds/symlink/lm386.pdf">LM386N</a> or similar</td>
                    <td>Amplify audio signal</td>
                </tr>

                <td>Resistors</td>
                    <td>1</td>
                    <td>10kΩ</td>
                    <td>For power amp.</td>
                </tr>
                <td>Potentiometer</td>
                    <td>1</td>
                    <td>500kΩ</td>
                    <td>For Volume control</td>
                </tr>
                <tr>
                    <td>Capacitors</td>
                    <td>2</td>
                    <td>0.33μF, 220μF</td>
                    <td>For power amp.</td>
                </tr>
                
                <!-- GUI Components -->
                <tr class="section-header">
                    <td colspan="4"><strong>GUI Components</strong></td>
                </tr>
                <tr>
                    <td>OLED SPI Display</td>
                    <td>1</td>
                    <td>Any display that uses  Adafruit SSD1306 drivers <a href= "https://midasdisplays.com/shop/oled/oled-graphic/mdob128064bv-ws/"> e.g. MDOB128064BV-WS</a></td> 
                    <td>Display synthesizer parameters</td>
                </tr>
                <tr>
                    <td>Joystick</td>
                    <td>1</td>
                    <td>With push button <a href= "https://cdn.velleman.eu/downloads/29/vma315_a4v01.pdf"> e.g. VMA315</a></td>
                    <td>Menu navigation</td>
                </tr>

                <!-- Drum Section -->
                <tr class="section-header">
                    <td colspan="4"><strong>Drum Machine Components</strong></td>
                </tr>
                <tr>
                    <td>Touch sensor</td>
                    <td>4</td>
                    <td>Capacitive touch sensor such as <a href= "https://wiki.dfrobot.com/DFRobot_Capacitive_Touch_Sensor_SKU_DFR0030">DFRobot v2</a></td>
                    <td>Drum trigger pads</td>
                </tr>
            </tbody>
        </table>
    </section>
    
    <section class="project-overview">
        <h2>Project Overview</h2>
        <p>The main goal of this project was to utilize an analogue 
            component with an embedded component to create a system that 
            functionally produces and processes audio signals for musical applications. 
            Our system integrates the envelope components of the synthesizer 
            with the touch pads of the drum set to create a model of a DJ set that 
            allows for real-time sound creation and manipulation. This project 
            demonstrates the use of practical applications in circuit design as well
             as developing and processing audio signals for output, combining analog 
             signal conditioning with digital control systems.</p>
    </section>

    <section class="Lesson 1: Play around with sound.">
        <h2>Lesson 1: Play around with sound.</h2>
        <p>Originally we set out to make a vocoder for this project, but after much testing and consideration we decided to 
            pivot. Some of the elements we built however, remained useful. The first thing we built was an audio power amplifier, 
            so that we could experiment with playing different sounds through it, and how different filters would affect the audio.
            You can try connecting the <strong>green wire</strong> to different types of input and playing with the volume controls.

            <object type="image/svg+xml" data="interactive_elems/power_amplifier.svg" class="project-image">
                Your browser does not support SVG
            </object>

            <ul>
                <li><strong>LM386 IC:</strong> This integrated circuit amplifies the weak audio signal to a level that can drive a speaker.</li>
                
                <li><strong>500kΩ Potentiometer:</strong> This serves as our volume control, allowing us to adjust the amount of audio signal that reaches the amplifier. Turning this knob adjusts the amplitude of the output sound.</li>
                
                <li><strong>0.33μF Capacitor (Input):</strong> This capacitor blocks DC voltage while allowing AC audio signals to pass through, preventing DC offset from affecting the amplifier.</li>
                
                <li><strong>220μF Capacitor (Output):</strong> This large electrolytic capacitor couples the amplified audio signal to the speaker while blocking DC current.</li>
                
                <li><strong>8Ω Speaker:</strong> The final component in our chain converts the electrical signal from the amplifier into sound waves we can hear. The 8Ω impedance matches well with the LM386's output characteristics.</li>
            </ul>
            To experiment with the power amp, you can connect the input of the circuit to a PWM pin on an Arduino and use the "tone.h" library to play different frequencies.
        
        </p>
    </section>

    <section class="Lesson 2:  Tunable Polysynth with ADSR">
        <h2>Lesson 2: Tunable Polysynth with ADSR</h2>
        <img src="imgs/keyb_synth.jpeg" alt="Featured image" class="featured-image">
        <p>
            Our goal in this lesson is to turn eight push‑buttons (or a tiny
            telephone‑style keypad) into a <strong>two‑voice digital synthesizer</strong>
            that feels surprisingly “analogue” thanks to a full ADSR envelope and
            rich lookup‑table waveform.  Everything runs on the Arduino Nano 33 IoT
            driving an <em>MCP4922</em> 12‑bit DAC, filtered, then boosted by a modest
            op‑amp/LM386 stage.  When you finish this page you’ll be able to play
            chords, tweak attack &amp; release in real time, and hear clean,
            artefact‑free notes through a speaker.
        </p>
        

        <img src="interactive_elems/SYNTH_bb.svg"
             alt="Poly‑synth build photo"
             class="project-image">

        
        <h3>Controls at a glance</h3>
        <ul>
            <li><strong>Pot A&nbsp;(Fine Tune)</strong> – shifts the whole scale up or
                down about ±40 %. Great for quick pitch‑bend effects or matching other
                instruments.</li>
            <li><strong>Pot B&nbsp;(Semitone)</strong> – nudges each note in 25‑cent
                steps across ±3 semitones. Handy for temperament experiments.</li>
            <li><strong>Pot C&nbsp;(Attack)</strong> – how fast the note rises from
                silence to full level (0.1 ms → 200 ms).</li>
            <li><strong>Pot D&nbsp;(Decay)</strong> – rate that the level slides down
                to the sustain plateau (captured per note).</li>
            <li><strong>Pot E&nbsp;(Sustain)</strong> – steady volume while a key is
                held (0 → 100 %). Also captured per note so later tweaks don’t affect
                existing sustains.</li>
            <li><strong>Pot F&nbsp;(Release)</strong> – fall‑off time once the key is
                released (0.1 ms → 200 ms).</li>
        </ul>
        
        <p>
            The <strong>eight note buttons</strong> map to a one‑octave A‑major scale:
            A4&nbsp;→&nbsp;A5 (A, B, C♯, D, E, F♯, G♯, A).  
            Because we store the scale as offsets from A4, the synth can easily transpose.
            Use the <strong>Oct ▲</strong> and <strong>Oct ▼</strong> buttons (pins A7
            &amp; A6) to shift the entire keyboard ±4 octaves.
        </p>
        
        <h3>Circuit overview</h3>
        <p>
            The Nano’s SPI bus clocks data into the MCP4922 at 8 MHz.  We use only
            channel A (12‑bit resolution).  A simple RC low‑pass pulls the
            stair‑stepped output down to audio‑bandwidth, and a unity‑gain
            <em>MAX417</em> buffers the line before it reaches the LM386 power amp.
            Frequency pots (A0 &amp; A1) feed 10‑bit ADC readings directly into the
            firmware’s tuning maths, while four more pots land on A2–A5 for the
            envelope knobs.  Eight buttons on D2‑D9 trigger the note logic; two
            extra buttons on A6/A7 bump the octave.
        </p>
        
        <table class="components-table">
            <thead><tr><th>Poly‑Synth‑only parts</th><th>Qty</th><th>Notes</th></tr></thead>
            <tbody>
                <tr><td>MCP4922 12‑bit DAC</td><td>1</td>
                    <td><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/22250A.pdf">datasheet</a>,
                        channel A used</td></tr>
                <tr><td>MAX417 (or any rail‑to‑rail op‑amp)</td><td>1</td>
                    <td>Unity buffer / RC low‑pass</td></tr>
                <tr><td>10 kΩ potentiometers</td><td>6</td>
                    <td>Attack, Decay, Sustain, Release, Fine‑tune, Semitone</td></tr>
                <tr><td>12‑key silicone keypad<br>(or 8 push‑buttons)</td><td>1</td>
                    <td>Note triggers</td></tr>
                <tr><td>RC filter</td><td>1 × 10 kΩ + 1 µF</td>
                    <td>1st‑order low‑pass ≈ 16 Hz f<sub>c</sub></td></tr>
                <tr><td>LM386, speaker, vol pot</td><td>1 set</td>
                    <td>Reuse from Lesson 1 amp</td></tr>
            </tbody>
        </table>
        
        <h3>Firmware deep‑dive</h3>
        
        <details>
        <summary><strong>Code anatomy (click to expand)</strong></summary>
        <ul>
            <li><code>rich_lookup_table[256]</code> – a pre‑cooked additive‑synthesis
                waveform. 256 samples keeps the phase counter byte‑sized and speeds
                table fetches.</li>
        
            <li><code>struct Voice</code> – holds everything per note:
                <ul>
                    <li><em>phase / phaseIncrement</em> – fractional 0‑255 counter that
                        indexes the table.</li>
                    <li><em>envState / envLevel</em> – live ADSR state machine.</li>
                    <li><em>decayTarget &amp; sustainLevel</em> – captured from the pots
                        at note‑on so decay really <em>isn’t</em> tied to sustain.</li>
                </ul>
            </li>
        
            <li><code>updateEnvelope()</code> – runs every sample. Key idea: during
                DECAY we subtract <code>env_decay</code> until <code>envLevel</code>
                hits <code>decayTarget</code>, then snap to
                <code>sustainLevel</code>. RELEASE is a straight linear fall under
                <code>env_release</code>.</li>
        
            <li><code>generateAudio()</code>
                <ul>
                    <li>Calls <code>updateEnvelope()</code>.</li>
                    <li>**Pitch math:** <code>phase += phaseInc</code>; if over 255,
                        wrap.</li>
                    <li>Weighted mix = 0.55 × voice0 + 0.45 × voice1. (Add 2048 to
                        recenter for the DAC.)</li>
                </ul>
            </li>
        
            <li><code>checkInputs()</code> – polled every 100 ms.
                <ul>
                    <li>Updates <em>baseFreqMultiplier</em> (fine tune) and
                        <em>semitoneRatio</em> from the pots.</li>
                    <li>Live‑tweaks Attack &amp; Release rates.</li>
                    <li>Debounces 8 note buttons + octave up/down.</li>
                </ul>
            </li>
        
            <li><code>triggerNote()</code>
                <ul>
                    <li>If the same note already plays, it re‑arms that voice (re‑phase,
                        envelope back to ATTACK).</li>
                    <li>Otherwise chooses a free/round‑robin voice.</li>
                    <li>Computes frequency&nbsp;→ <code>phaseIncrement</code> via  
                        <br><code>(freq × 8.4) / 1000</code>, clipped ≤ 128.</li>
                    <li>Captures decay &amp; sustain pot values into the voice.</li>
                </ul>
            </li>
        
            <li><code>updateAllVoiceFrequencies()</code> – called when tuning pots or
                octave change: recalculates every active voice’s
                <code>phaseIncrement</code> so chords stay in tune.</li>
        </ul>
        </details>
        
        <h3>Key techniques</h3>
        <ul>
            <li><strong>Per‑note phase randomisation</strong> – new note seeds its phase
                from <code>seedValue % 256</code> so two identical notes don’t cancel.</li>
            <li><strong>Slew‑free tuning</strong> – by updating the
                <code>phaseIncrement</code> directly, pitch bends have no zipper noise.</li>
            <li><strong>Pitch droop compensation (optional)</strong> – if you notice
                frequencies sagging during DECAY or RELEASE, uncomment the
                <code>// BOOST</code> line in <code>generateAudio()</code> and set
                <code>currentPhaseInc *= 1.05;</code>.</li>
        </ul>
        
        <h3>Build &amp; test</h3>
        <ol>
            <li>Wire the DAC: SCK→D13, MOSI→D11, CS→D10, LDAC→GND, V<sub>REF</sub> &amp;
                V<sub>DD</sub>→3V3.</li>
            <li>RC low‑pass 10 kΩ + 1 µF, then buffer with MAX417 (or TLV2462).</li>
            <li>Feed the op‑amp into your LM386 amp from Lesson 1.</li>
            <li>Hook up six pots (A0–A5) and keypad/buttons (D2–D9).</li>
            <li>Flash the sketch below, open Serial Plotter (you’ll see the envelope),
                then play chords &amp; twist knobs.</li>
        </ol>
        
        <div class="code-container">
            <div class="code-header">
                <span>Arduino Poly-Synth.</span>
                <span class="code-language">C++</span>
            </div>
            <pre><code id="synth-code" class="language-cpp" data-src="code_snippets/synth_code.ino"></code></pre>
        </div>
    </section>
               
    

    <section class="Lesson 3: Drum Kit"> 
        
        
            <h2>Lesson 3: The Drum Kit</h2>
            <object type="image/svg+xml" data="interactive_elems/drum kit_bb.svg" class="project-image">
                Your browser does not support SVG
            </object>
            <p>The drum machine lets us play drums and sound effects</p>
            <p> 
                The drum kit uses 16 bit 22kHz lookup tables to play drum sounds.
                To ensure that the lookup tables were correct we used some that we found on github
    
               <a href= "https://github.com/spanceac/electro-drums/tree/master/samples"> here</a>.

                This allowed us to make sure our own code was working, without wondering wether the issue was our lookup tables. 
                <br><br>
                <h4>How the PWM works</h4>
                To play these sounds we used a pulse width modulation (PWM) configured pin on the PICO (pin 0), 
                this could be done using a digital to analog converter (DAC), as used in our synth. Ultimately, 
                The decision to use PWM was taken to reduce the number of components and complexity. A low pass filter was 
                used on the pwm output to smooth out the signal further. This can be seen on the breadboard diagram 
                <br><br>
                Although the samples are 16 bit, in order for the PWM output to keep up with the 22kHz sample rate 
                ,we have to reduce the actual PWM resolution to 12 bit.
                <br><br>
            
                As the resolution of a PWM signal increases, the number of “time slots” in each PWM cycle at which the pulse can be turned off increases. 
                For 12 bit this value will be 4096, and for 16 bit it is 65536. This means that If we wanted to use the PWM to play 16-bit audio samples at 22kHz, 
                we would  effectively need to be able to count from 0 - 65,536 at least 22 thousand times a second. 
                This is not possible with the 125MHz clock speed of the PI PICO. 
                So rather than passing the 16 bit samples to the PWM, we will pass 12 bit values (after the audio sample mix) to play. 
                The following code snippet shows how we do this mapping before passing the value to the PWM.


            </p>
            <!-- Drum set description content here -->
            
            <div class="code-container">
                <div class="code-header">
                    <span>Mapping the mix to 12 bits</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
// dont let the total mixed value go over 16 bits
// just set it to the max if it goes over
if (samp_sum < -32768) {
    samp_sum = -32768;
} 
else if (samp_sum > 32767) {
    samp_sum = 32767;
}
                    
// Map from [-32768, 32767] to [0, 4096] (signed 16 bit to unsigned 12 bit)
int32_t shifted_mix = (int32_t)mix + 32768;         // shift all of the values to be positive
int16_t scaled_mix = shifted_mix * 4096;            // mulitply by our PWM range
uint16_t pwm_val = (uint16_t)(scaled_mix / 65536);  // scale it back down to the [0, 4096]
// UNSIGNED for pwm!!

pwm_set_gpio_level(pwm_output_pin, pwm_val);
                </code></pre>
            </div>
            
            <h4>The GPIO's</h4>

            <p>  
                There are two types of GPIO inputs, the capacitive touch sensors which trigger the drum sounds, and then the pushbuttons 
                which we use to enter record mode and playback mode. Regardless of which GPIO is pressed we will enter the same interrupt service routine, 
                this just reduces the codes complexity at the cost of some performance.
                <br>
                An important distinction between the buttons and the touch sensors is that the buttons are active low and the touch sensors are active high. 
                This means we must set the buttons to be falling edge interrupts and the touch sensors to be rising edge interrupts.
                For the functions that are used in this code snippet, you will need the pico-sdk.
            </p>

            <div class="code-container">
                <div class="code-header">
                    <span>Setting the GPIO interupts</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
// Set up the touch pads for interupts
for (int i = 0; i < num_pads; i++) {
    gpio_init(Drum_Pads[i]);
    gpio_set_dir(Drum_Pads[i], GPIO_IN);
    
    // Use with_callback for all touch sensors
    gpio_set_irq_enabled_with_callback(Drum_Pads[i],        // cycle through all the pads
                                        GPIO_IRQ_EDGE_RISE,   // set at rising edge interupt
                                        true,                 // we want the interupt to be working
                                        &gpio_isr);           // use the gpio_isr function as a callback
}

// Set up the pushbuttons for interupts
for (int i = 0; i < num_buttons; i++) {
    // Configure pin as input with pull-up resistor
    gpio_init(pusshbuttons[i]);
    gpio_set_dir(pusshbuttons[i], GPIO_IN);
    gpio_pull_up(pusshbuttons[i]);              // set a pullup resistor
    
    // Enable interrupt for falling edge (button press) and set callback
    // callback not needed as they should default to the previously set callback
    // included in case someone wishes to use only buttons in there project
    gpio_set_irq_enabled_with_callback(pusshbuttons[i], 
                                       GPIO_IRQ_EDGE_FALL, 
                                       true, 
                                       &gpio_isr);
}
                </code></pre>
            </div>


            <h4>Playing Samples</h4>
            <p> 
                To decide if a sample is currently playing, we set bits. 
                This could be achieved with just an array of bools, but the binary operations are a more interesting 
                approach that has the added benefit of being faster.This means we need 3 functions
                <br>                
                <ul>
                    <li>Set a bit (tell the code that a sound is playing)</li>
                    <li>Clear a bit (if a sound should stop playing)</li>
                    <li>Check a bit (to see if a specific sound is playing)</li>
                </ul>
                The code for these functions can be seen in a snippet below. Note that it is very 
                important to use the "voltile" keyword for the track_bitmap. This is because this holds
                the bits that will actually be set or cleared depending on the samples that are currently
                playing. This means that it can change depending on the gpio interupts that the CPU will not anticipate.
            
            </p>

            <div class="code-container">
                <div class="code-header">
                    <span>Binary operation functions</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
void bit_set(volatile uint32_t *track_bitmap, uint8_t tracknumber) {
    // OR the track bit position with 1 to set it
    *track_bitmap |= 1 << tracknumber;
}

void bit_clr(volatile uint32_t *track_bitmap, uint8_t tracknumber) {
    // AND the track bit position with 0 to clear it
    *track_bitmap &= ~(1 << tracknumber);
}

uint8_t testbit(uint32_t track_bitmap, uint8_t tracknumber) {
    // shift everything right by our track nunber and chekc its value
    // AND with the mask 
    return (track_bitmap >> tracknumber) & 0x01;
}
                </code></pre>
            </div>

            <h4> 
                Putting these together
            </h4>
            <p> 
                Now that we have gpio interupts and the binary operations, we can set bits using our touch pads.
                This is done inside of the gpio_isr in the following lines
            </p>
            <div class="code-container">
                <div class="code-header">
                    <span>Setting a track to play</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
void gpio_isr(uint gpio, uint32_t events) {
    . 
    . 

    if (is_touch_sensor) { // if the interupt was triggered by a touch sensor (drum pad)
        . 
        . 
        .
        bit_set(tracks_playing, touched_pad);                              // set the track to play
        samples_left_to_play[touched_pad] = total_samples[touched_pad];    // Initiall, our samples left to play is ALL of the samples  
        . 
        return
    }
    . 
    . 
}
                </code></pre>
            </div>


            <h4>How the audio actually plays</h4>
            <p> 
                A repeating_timer object is used to trigger a time interupt 22 thousand times a second.
                this allows us to change the PWM to ouptut the next sample at 22kHz. There is a code snippet below that 
                contains the logic we used to move from sample to sample at the sample rate.
                <br><br>
                The general idea is as follows:<br> 
                <ol>
                    <li>When it is time to move to the next sample</li>
                    <li>Check which tracks are currently playing</li>
                    <li>For each track that is playing, add its next sample to a running "mix" sum</li>
                    <li>Decrement how many samples are left to play for that track</li>
                </ol>
                This value is then bounded inside [0,4095] as seen earlier, before being passed to the PWM.
            </p>
            
            <div class="code-container">
                <div class="code-header">
                    <span>Playing Samples and mixing</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
int32_t samp_sum = 0;   // 32 bit integer for the raw sum of the samples
                    
// figure out which tracks are playing 
for (int i = 0; i < TRACK_NR; i++) { // for every track we have

    if (testbit(tracks_playing, i) == 1) { // if it is currently playing

        // get the index of the sample we need to play
        uint32_t current_sample_index = total_samples[i] - samples_left_to_play[i];

        // if we still have samples left to play
        // and if the index is valid
        if (current_sample_index < total_samples[i] && tracks[i] != NULL) {  
            samp_sum += tracks[i][current_sample_index];
            samples_left_to_play[i]--;  // Decrement number of samples left to play
            
            if (samples_left_to_play[i] <= 0) {
                bit_clr(tracks_playing, i);  // Finished playing this track
            }
        } else {
            // we have completed playing that sample so just exit now
            bit_clr(tracks_playing, i); // clear the bit so that we wont keep trying to play this track
        
        }
    }
}
                </code></pre>
            </div>

        <h4>Making Drum Loops</h4>
        <pr> 
            IF you’d like to be able to set up drum loops, this section will outline how we did it. 
            First we created a class called a LoopEvent, which contain two member variables; track and timestamp. 
            This means that we can hold what drum has been triggered, and the time it was triggered at. 
            <br><br>
            To enter the mode where you can input the loop, there is a button and LED which can light up to indicate that we are in the recording mode. In the code this can just set a bool value to true. From here we enter a separate section of the code that does not just play the drum sounds but will record them as a LoopEvent and add them to an array.
            
            <ul>
                <li>Track - what drum sample was triggered</li>
                <li>Timestamp - time in mullisends since the loop started</li>

            </ul>
            
            The code snippet below will go inside of the gpio_isr, It will only be called however if the record_mode boolean
            is set to true.
        </pr>
            
            <div class="code-container">
                <div class="code-header">
                    <span>Setting a track to play</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
// Add an event to the loop
void add_loop_event(uint8_t track) {
    if (loop_event_count < MAX_LOOP_EVENTS) {
        uint64_t current_time = time_us_64();
        uint64_t triggered_time = current_time - loop_start_time;
        
        loop_events[loop_event_count].track = track;
        loop_events[loop_event_count].timestamp = triggered_time;
        loop_event_count++;
    }
}
                </code></pre>
            </div>

            <pr>This then calls for a playback function, that can read in this array of LoopEvents and 
                play the drum sounds at the correct times.
                <br>
                This is done once again using a repeating_timer object, that repeats every 1 millisecond. 
                If in playmode, this will then enter a check_loop_events() function, that will determine if a 
                drum should be playing. If it determines that it should be, then it sets the bits necessary to 
                signal to the program that those tracks are now playing.<br>
                This will be handled by the portion of our code that checks what should be playing every 22kHz.
                <br><br>
                The general idea for this function should be:
                <ol> 
                    <li>If we are in the playback mode</li>
                    <li>If any Loop Events should play in this timeslot</li>
                    <li>Set the bits corresponing to the tracks that should play</li>
                    <li>If we have played the entire loop, replay it</li>

                </ol>

                In practice we found that sometimes the repeating timer would some loops because it would be a millisencond or two late.
                To combat this we added a window of time. Essentially saying that if any, tracks were due to play in the last 5 milliseconds,
                set there bits. The reason that this works is that set bits to signify if a track is playing, not that it should start playing when we set it.
                <br> 
                This means that we can set a bit multiple times if we check the loop 4 times in the 5ms. This is fine as the number of samples 
                left to play for each track is handled seperately, and setting these bits again does not interfere with it at all.

                <br><br> 
                So our final function for finding and playing loop events is shown below.

            </pr>

                <div class="code-container">
                    <div class="code-header">
                        <span>Playing the loop</span>
                        <span class="code-language">C</span>
                    </div>
                    <pre><code class="language-C">
void check_loop_events() {

    // if we are in the playback loop mode
    // and if we have something in the loop
    if (play_mode && loop_duration > 0) {

        // loop through all of the loop events
        for (int i = 0; i < loop_event_count; i++) {

            // check if each event should have played yet,
            // have a window just to make sure we dont miss any of the beats, (even if they are slightly incorrectly timed)
            if (loop_events[i].timestamp <= loop_timestamp && 
                loop_events[i].timestamp > loop_timestamp - 5000) { // 5ms window

                uint8_t track = loop_events[i].track; // get the track that we should be playing

                if (track < TRACK_NR) { // if its an actual track
                    bit_set(tracks_playing, track);
                    samples_left_to_play[track] = total_samples[track];
                }
            }
        }
        
        // if we have completed the loop then set the timestamp back to zero so we start again
        if (loop_timestamp >= loop_duration) {

            loop_timestamp = 0; 
            
        }
    }
}
                    </code></pre>
                </div>
            
            <h4>Adding sound effects!</h4>
            <pr>
                This was done by once again adding another button, which would put us into a “sound selection mode”.
                The approach of our group was that when in this mode, you can repeatedly tap a touch pad to cycle 
                through the available sounds. 
                
                The goal for this functionality was as follows:
                <ol>
                    <li>Tap the button to enter sound selection mode</li>
                    <li>Cycle through the available sounds on any gpio you want</li>
                        <ul>
                            <li>Play a sample each time so that we know what we are selecting</li>
                        </ul>
                    <li>When we are done reconfiguring, tap the same button to solidify all of the tracks assigned to each button</li>
                </ol>
            </pr>

            <div class="code-container">
                <div class="code-header">
                    <span>Configuring the Drum Pads </span>
                    <span class="code-language">C</span>
                </div>
                <pre><code class="language-C">
void gpio_isr(uint gpio, uint32_t events) {
    . 
    . 
    . 
    if (is_touch_sensor) {
        . 
        . 
        .
        if (sound_select_mode) {
            if (current_button_to_configure == touched_pad) {
                // Button already selected, cycle through available sounds, make sure to wrap around
                currently_selected_sound = (currently_selected_sound + 1) % total_num_tracks;

                // switch the track that is currently assigned to the pad
                button_sound_mapping[touched_pad] = currently_selected_sound;
                
                // update how long the samples are so that the sound playing works
                total_samples[touched_pad] = available_sounds_sizes[currently_selected_sound];

                // change the current list of tracks that we play
                tracks[touched_pad] = available_sounds[currently_selected_sound];
                
                // Play the new sound so we can hear what we are selecting 
                bit_set(tracks_playing, touched_pad);
                samples_left_to_play[touched_pad] = total_samples[touched_pad];
                
            } else {
                // just touched a new pad
                // set it as the drum pad we are currently configuring
                current_button_to_configure = touched_pad;

                // update the array that holds the sound currently corresponding to each touch pad
                currently_selected_sound = button_sound_mapping[touched_pad];   
                
                // Play the current sound before we make any changes
                bit_set(tracks_playing, touched_pad);
                samples_left_to_play[touched_pad] = total_samples[touched_pad];
            }
            return;
        }
        . 
        . 
    }
    . 
    .
}
                </code></pre>
            </div>

            <h4>Some bits we left out</h4>

            <p> 
                There are some bits of code we left out here to make it more easy to digest, The full code files
                will be available below. But there are a few things to note:

                <ol>
                    <li>The preprogrammed beat functionality</li>
                        <ul>
                            <li>This is just a matrix containing pre-computed loops</li>
                            <li>It uses the LoopEvent class that was previously mentioned</li>
                            <li>It is controlled by teh GUI</li>
                        </ul>
                    <li>The gpio_isr triggering handling the boolean values</li>
                    <li>The timer callback functions that handle both the:</li>
                        <ul>
                            <li>Replaying the samples at 22kHz</li>
                            <li>Recording and replaying loops</li>
                        </ul>
                </ol>
            </p>

            <div class="code-container">
                <div class="code-header">
                    <span>Pico-SDK for drum kit</span>
                    <span class="code-language">C</span>
                </div>
                <pre><code id="drums-pico-code" class="language-c" data-src="code_snippets/PICO_drums.c"></code></pre>
            </div>
            
    </section>

        <section class="Lesson 4: Converting YouTube Videos to Drum Samples.">
            <h2>Lesson 4: Converting YouTube Videos to Drum Samples.</h2>
            <p>
                A fun thing to do is to create your own drum samples from sounds/songs that you like. The easiest way to do this is to
                download an <code>`.mp3`</code> version (or use your own mp3) of a song/sound from YouTube. Sites such as <a href="https://youtubemp3free.com/en/">this one</a> can convert them for free.
                Once you have an mp3 file, it needs to be converted to <code>`.wav`</code> format. Sites such as <a href="https://www.freeconvert.com/mp3-to-wav">this one</a> can convert them for free. 
                <br>
                <br>
                We wrote a script that converts the wav file into a format that is compatible with our drum kit: an array of 16-bit integers (same format as drum samples).
                The script generates a C header file that can be included in the drum kit code to make that sample available. Samples are limited to 4 seconds, which allowed us to fit three samples onto the Pico due to memory contraints.

    
    
                <div class="code-container">
                    <div class="code-header">
                        <span>Python code for song converter.</span>
                        <span class="code-language">python3</span>
                    </div>
                    <pre><code id="song-converter" class="language-python" data-src="code_snippets/song_converter.py"></code></pre>
                </div>
                Below is the output header file for a "Rick-roll". By including this in the drum kit code, it can be used as a drum 
                sample.
                <div class="code-container">
                    <div class="code-header">
                        <span>Song converted into header.</span>
                        <span class="code-language">C</span>
                    </div>
                    <pre><code id="rick-roll-header" class="language-c" data-src="code_snippets/rick_roll.h"></code></pre>
                </div>
            </p>
        </section>
    
    <section class="Lesson 5: Create a GUI.">
        <h2>Lesson 5: Create a GUI.</h2>
        <p>
            A graphical user interface (GUI) can really improve the user experience, here the GUI serves a few functions. Firstly, it displays the current properties set on the ADSR for tuning.
            It also functions as an oscilloscope, and can display the wave that is being generated by the keyboard synthesizer.
            By using the click functionality on the joystick, a user can select from a list of preprogrammed drum loops, which will start playing on the drum via the Pico!
            Navigation through the GUI works with the flick of the joystick, by flicking left or right, you can cycle through the different screens.
            By flicking up and down, you can cycle through the different preprogrammed drum loops and songs.
            <object type="image/svg+xml" data="interactive_elems/synth_GUI_bb.svg" class="project-image">
                Your browser does not support SVG
            </object>
            <ul>
                <li><strong>Arduino:</strong> The Arduino Uno controlls the GUI states, sends state updates to the Pico and refreshes the OLED display. This could be run on the same Arduino as the synthesizer or even on the Pico. We did experiment with running the GUI on the second core of the Pico, but because of a lack of analogue input GPIO pins, and no library support for the Adafruit OLED displays, this did not work. It would have been simple to also run the GUI on the Arduino Nano, where the synthesizer runs, however, again because of a limit on GPIO pins and clock constraints (the Nano was not fast enough to get sufficient wave resolution and run the GUI) this was abandoned. If we were to do this project again, we would use just one microcontroller with more computational power to run the synthesizer and the GUI. </li>
                
                <li><strong>Joystick:</strong> The joystick is used to navigate the GUI through three analogue inputs: displacement in x, displacement in y, and clicking of the joystick. In the code there are limits defined for what displacement of the joystick is considered a 'flick'. These flicks are used to navigate through the different menus and also between songs/drum loops within menus. When a user wants to select a song, they can click in on the joystick. This click is debounced, and depending on the state of the screen (which drum loop/song they were hovering over), the selected drum loop/song will be updated. Every time a selection is updated this is passed to the Pico.</li>
                
                <li><strong>Output wires:</strong> The white, orange, ochre, and purple wires in the schematic (connected to digital GPIO pins) are the functinonal connections to the Pico. They relay the update drum/song choice to the Pico. In our implementation, this works simply but outputting a 'high' to a wire corresponding to each possible drum selection. In the future, it would be better to serialize the selection.</li>
                
                <li><strong>OLED display:</strong> The OlED display runs on the Adafruit SSD1306 library over serial peripheral interface (SPI). There is great support of this screen on the Arduino, using the SPI library and the Adafruit screen library. Using the built in functions of these libraries, custom screens can be drawn and displayed on the screen based on state variables. This is the main premise of the code implementation, discussed below.</li>
                
            </ul>


            <div class="code-container">
                <div class="code-header">
                    <span>Arduino Code for GUI</span>
                    <span class="code-language">C++</span>
                </div>
                <pre><code id="gui-arduino-code" class="language-cpp" data-src="code_snippets/gui_arduino_code.ino"></code></pre>
            </div>
            At it's core the GUI is driven by one state variable: <code>`screen_state`</code>, which ranges from 1-5, and denotes the current screen that will be displayed: a main menu, synthesizer controls, oscilloscope, song selector, and drum selector. The chooseScreen() function continuously reads the joystick's X-axis: pushing right increments <code>`screen_state`</code>, pushing left decrements it, and it wraps around when it goes beyond either end. Each loop iteration then calls <code>`drawScreen()`</code>, which dispatches to the appropriate drawing function for the current mode.
            For selecting and playing preprogrammed drum loops <code>`(screen_state == 5)`</code>, the joystick's Y-axis moves a highlighted box through up to four entries ("Money beat", "Hip-Hop", "Funk", "None"), while a click of the joystick button(debounced) commits a choice into <code>`selected_song`</code>. The selected song is conveyed to the Pico, to play the drums.
            Throughout the code, "dead-zone" thresholds prevent jitter when the joystick is centered, and brief delay(100) calls debounce menu transitions.
            
        </p>
    </section>


    <section class="How-Do-The-Components-Work?">
        <h2>Lesson 6: Bringing it all together.</h2>
        <div style="text-align: center;">
            <img src="imgs/Full_DJ_Set_Picture.jpg" alt="labelled imge" class="labelled-image"width="750" height="500" style="border: 3px solid black;">
        </div>
        <p>Our DJ table consists of three main hardware components working together to
             create a complete music production system. This section contains 
             information on how to construct and integrate the final components.</p>

             <li>Keyboard Synthesizer featuring an ADSR (Attack, Decay, Sustain, Release) 
                envelope controller, a 12-key numeric keypad interface, operational amplifier 
                circuitry for signal conditioning, a digital-to-analog Converter (DAC) for
                waveform generation.</li>
            <div style="text-align: center;">
                <img src="imgs/Labelled_Synth.jpeg" alt="labelled image" class="labelled-image" width="500" height="475" style="border: 3px solid black;">
            </div>
            
            <li>GUI features a real-time oscilloscope to vizualize the audio waveform,
                 synthesizer screen with percentage bars to monitor ADSR values, and drum and song selection screens
                 to view the selected drums/song from a list of preloaded sounds</li>
    
            <!-- need a labelled picture of the GUI here -->   
            
            <li>Drum Set including 5 capacitive touchpads to play sounds such as snare, kick, hi-hat, and audio samples. Pad assignments can be programmed on the fly by the user, looping through sound options. It has recording capabilities allowing the user to create a loop of sounds, that they can then play additional sounds over. </li>

        
        <div class="component-section">
            <h3>Summing Amplifier</h3>
            <div style="text-align: center;">
                <img src="imgs/NBMetadataCache.jpeg" alt="labelled imge" class="labelled-image" width="750" height="200">
            </div>
            <p>In order to combine all the sounds from the DJ set into a single speaker, a summing amplifier is used.
                This component takes 2 audio inputs, one from the drum-kit (including audio samples) and the other from synthesizer, and mixes 
                them into a single output signal that is then sent to the power amplifier and then the speaker.</p>
            </div>
            <div class="component-section">

                <object type="image/svg+xml" data="interactive_elems/full_DJ_deck_bb.svg" class="project-image">
                    Your browser does not support SVG
                </object>
                <p> The schematic above illustrates how all components are interconnected to form a cohesive audio system, 
                    representing the completed project fully integrated into a functional DJ set. On the right, the synthesizer 
                    circuit generates analog audio signals controlled by the ADSR, while the drum module on the left produces 
                    digital drum sounds that are converted to analog using a DAC. Both of these outputs are fed into a summing 
                    amplifier in the middle, which combines the signals into a single output that drives the speaker on the 
                    far left. The GUI, located on the blue tray above, has the ability to play prerecorded songs and beats, as 
                    well as display a simplified oscilloscope to visualize changes in the electrical signal over time. </p>
            </div>

        </div>
        
    </section>

    
    <section class="conclusion">
        <h2>Thank you for following!</h2>
        <p>
            We hope you enjoyed following this blog about our 3C10 Circuits and System project's design process.
        </p>
    </section>
    
    <footer>
        <p>© 2025 Ruairi Mullally, Otis Doran, Aidan McNeill, & Brandon Kekedjian  | Trinity College Dublin</p>
        <p>Created for 3C10 - Circuits & Systems Design</p>
    </footer>
</body>
</html>